# Fly.io configuration for EMOGUCHI backend
app = "emoguchi-backend"
primary_region = "nrt"  # Tokyo region for lower latency

# Build configuration
[build]
  dockerfile = "docker/backend.Dockerfile"

# Environment variables
[env]
  PORT = "8000"
  PYTHONUNBUFFERED = "1"
  STORAGE_TYPE = "s3"

# HTTP service configuration
[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0  # Scale to zero for cost savings

# Health check configuration
[http_service.checks]
  [http_service.checks.health]
    grace_period = "10s"
    interval = "30s"
    method = "GET"
    timeout = "10s"
    path = "/api/v1/solo/health"

# Machine configuration optimized for ML workload
[[vm]]
  cpu_kind = "shared"
  cpus = 2
  memory_mb = 2048

# Scaling configuration for cost optimization
[scaling]
  min_machines_running = 0
  max_machines_running = 3

# Secrets (set via fly secrets set)
# DATABASE_URL - Neon PostgreSQL connection string
# OPENAI_API_KEY - OpenAI API key
# R2_ENDPOINT_URL - Cloudflare R2 endpoint
# R2_ACCOUNT_ID - Cloudflare account ID
# AWS_ACCESS_KEY_ID - R2 access key
# AWS_SECRET_ACCESS_KEY - R2 secret key
# S3_BUCKET - R2 bucket name