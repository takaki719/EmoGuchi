# EMOGUCHI 現状仕様まとめ

## 1. 概要

**EMOGUCHI**は、リアルタイムの音声演技と感情推定を組み合わせたパーティゲームです。プレイヤーはスピーカーとして指定されたセリフを感情を込めて読み上げ、他のプレイヤー（リスナー）はその感情を推測してスコアを競います。

- **コンセプト**: 音声演技 × 感情推定ゲーム
- **主な目的**: 楽しみながら感情表現力と共感力を高める

## 2. コア機能

### 2.1. ゲームフロー

1.  **ルーム作成/参加**: プレイヤーはゲームルームを作成、または既存のルームに参加します。
2.  **ラウンド開始**: ホストがゲームを開始します。
3.  **お題提示**:
    *   LLM (OpenAI GPT-4o) が自動で「感情」と「セリフ」のお題を生成します。
    *   スピーカーにのみ「感情」が通知されます。
    *   全員に「セリフ」が公開されます。
4.  **演技フェーズ**: スピーカーは与えられた感情を込めてセリフを読み上げ、その音声を録音します。
5.  **音声共有**: 録音された音声がリスナー全員にリアルタイムで配信されます。（ボイスチェンジャーモードの場合、ここで音声が加工されます）
6.  **投票/判定フェーズ**:
    *   **マルチプレイモード**: リスナーは音声を聞き、スピーカーがどの感情で演じたかを推測して投票します。
    *   **ソロモード**: AIが演者の音声を分析し、感情を判定します。
7.  **結果発表**: 正解の感情、各プレイヤーの投票（またはAIの判定結果）、獲得スコアが表示され、1ラウンドが終了します。

### 2.2. ゲームモード

-   **マルチプレイモード**: 複数人で楽しむ基本のモード。
    -   **基本モード**: 8種類の基本感情から出題。
    -   **応用モード**: 24種類の複合感情から出題。
-   **ソロモード**: 1人用モード。プレイヤーの演技をAIが判定し、スコアを付けます。
-   **ボイスチェンジャーモード (高難易度オプション)**: マルチプレイモードに追加できるオプション。スピーカーの音声がランダムなエフェクト（ピッチ変更、速度変更、感情の印象を逆転させる加工など）で加工され、リスナーの推測をより難しくします。

### 2.3. スコアリング

-   **スピーカー**: 自分の感情を正しく当てたリスナーの数 × 1点
-   **リスナー**: 正解の感情を当てると +1点
-   **ソロモード**: AIの判定結果に基づいてスコアが計算されます。

### 2.4. 音声機能

-   **録音**: スピーカーはブラウザのMediaRecorder APIを使用して音声を録音します (形式: WebM/Opus)。
-   **配信**: 録音データはWebSocket (Socket.IO) を通じて、他のプレイヤーにバイナリデータとしてリアルタイム配信されます。
-   **再生**: リスナーは配信された音声データをブラウザ上で再生できます。

## 3. 技術スタック

| カテゴリ | 技術 | 目的 |
| :--- | :--- | :--- |
| **フロントエンド** | Next.js 14 (React), TypeScript | UI構築、型安全な開発 |
| | Tailwind CSS | 高速なUIスタイリング |
| | Zustand | シンプルなグローバル状態管理 |
| | Socket.IO Client | リアルタイム通信 |
| | MediaRecorder API | ブラウザ標準の音声録音 |
| **バックエンド** | FastAPI (Python) | REST API & WebSocketサーバー |
| | python-socketio | リアルタイム通信、バイナリデータ処理 |
| | OpenAI API | LLMによるセリフ生成 |
| | Pydantic | データバリデーション |
| | **Transformers, PyTorch** | **ソロモード用の音声感情認識AIモデル** |
| | **Librosa** | **ボイスチェンジャー機能の音声処理** |
| **インフラ** | Docker, Docker Compose | 開発環境のコンテナ化 |
| **ホスティング(想定)** | Vercel (Frontend), Railway/Render (Backend) | デプロイ先 |

## 4. アーキテクチャ

### 4.1. システム構成

-   **フロントエンド**: Next.jsによるSPA (Single Page Application)。
-   **バックエンド**: FastAPIサーバー。
-   **通信**:
    -   **REST API**: ルームの作成・状態取得など、管理系の操作。
    -   **WebSocket (Socket.IO)**: ゲームの進行、投票、音声データのリアルタイム配信など、インタラクティブな操作。

### 4.2. 状態管理

-   **ハイブリッドアプローチ**:
    -   **インメモリ**: ゲームのリアルタイム性を保つため、ルームやプレイヤーの状態はサーバーのメモリ上で管理。
    -   **データベース (PostgreSQL - 準備段階)**: 音声データや重要なゲーム結果などを永続化するための準備がされています (`StateStore`による抽象化)。

### 4.3. 主要APIエンドポイント (REST)

-   `POST /api/v1/rooms`: 新規ゲームルームを作成
-   `GET /api/v1/rooms/{roomId}`: 指定したルームの状態を取得

### 4.4. 主要WebSocketイベント

-   `join_room`: プレイヤーがルームに参加
-   `round_start`: 新しいラウンドの開始を通知
-   `audio_send`: スピーカーが録音した音声データを送信
-   `audio_received`: リスナーが音声データを受信
-   `submit_vote`: リスナーが投票を送信
-   `round_result`: ラウンドの結果を通知

## 5. セットアップと実行

Docker環境での起動が推奨されています。

1.  `.env.example` をコピーして `.env` を作成し、`OPENAI_API_KEY` を設定します。
2.  リポジトリのルートで以下のコマンドを実行します。
    ```bash
    docker-compose up --build
    ```
3.  以下にアクセスします。
    -   **フロントエンド**: `http://localhost:3000`
    -   **バックエンドAPIドキュメント**: `http://localhost:8000/docs`

## 6. 今後の拡張性

-   **データベースの本格導入**: 現在はメモリ管理が主ですが、`StateStore`という抽象化レイヤーを設けることで、PostgreSQLなどへの本格的な移行が容易になっています。
-   **ユーザー認証**: ユーザーごとの履歴管理などを見据えた機能拡張。
-   **リアルタイム音声ストリーミング**: 現在の「録音完了後に送信」方式から、WebRTCなどを利用したより低遅延なストリーミングへの移行も視野に入ります。
